{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4502ba42-29b5-4319-84b2-d1aaa94a410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime, UTC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import pickle\n",
    "import re\n",
    "from get_params import DATA_FOLDER, POSTS_FPATH, COMMENTS_FPATH, CURATED_DATASET_FPATH, TRAIN_DATASET_FPATH, VAL_DATASET_FPATH\n",
    "from get_params import MAX_TOKENS\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "INTERIM_OUTPUT_PATH = os.path.join(DATA_FOLDER, \"posts_comments_df_filtered.pkl\")\n",
    "OUTPUT_PATH = CURATED_DATASET_FPATH\n",
    "\n",
    "## Get HF tokenizer\n",
    "with open(os.path.join(DATA_FOLDER, \"hftoken.txt\")) as f:\n",
    "    HF_TOKEN = f.read().strip()\n",
    "\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    token=HF_TOKEN\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a474229-9de1-47c1-938c-27d4b0beb953",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_posts(fpath):\n",
    "    cnt = 0 \n",
    "    data_out = []\n",
    "    with open(fpath) as f:\n",
    "        for line in f:\n",
    "            pline = json.loads(line)\n",
    "            if (\n",
    "                (pline[\"is_self\"]) and (pline[\"selftext\"].strip() not in [\"[deleted]\", \"[removed]\", \"\"])\n",
    "                # exclude pinned posts and posts by mods\n",
    "                and (not pline.get('stickied', False)) and (pline[\"distinguished\"] != \"moderator\")\n",
    "            ):\n",
    "                cnt += 1\n",
    "                ## Build parsed dataset\n",
    "                # try:\n",
    "                title_contains_q = True if (\"?\" in pline['title']) else False\n",
    "                selftext_contains_q = True if (\"?\" in pline['selftext']) else False\n",
    "                title_ends_q = True if (pline['title'][-1] == \"?\") else False\n",
    "                selftext_ends_q = True if (pline['selftext'][-1] == \"?\") else False\n",
    "                pline_out = {\n",
    "                    'post_id': pline['id'],\n",
    "                    ## important content\n",
    "                    'title': pline['title'],\n",
    "                    'selftext': pline['selftext'],\n",
    "                    'link_flair_text': pline['link_flair_text'], # post flair\n",
    "                    'title_len': len(pline['title'].strip()), # length of title\n",
    "                    'selftext_len': len(pline['selftext'].strip()), # length of selftext\n",
    "                    ## potential measures of quality of posts and comments\n",
    "                    'score': pline['score'], # net upvotes\n",
    "                    'ups': pline.get('ups', np.nan), # raw upvotes\n",
    "                    'num_comments': pline['num_comments'], # number of responses/comments\n",
    "                    \"title_contains_q\": title_contains_q,\n",
    "                    \"selftext_contains_q\": selftext_contains_q,\n",
    "                    \"contains_q\": title_contains_q + selftext_contains_q,\n",
    "                    \"title_ends_q\": title_ends_q,\n",
    "                    \"selftext_ends_q\": selftext_ends_q,\n",
    "                    \"ends_q\": title_ends_q + selftext_ends_q,\n",
    "                    ## when was the post made?\n",
    "                    'created_utc': int(pline['created_utc']),\n",
    "                    'created_utc_dt': datetime.fromtimestamp(int(pline['created_utc']), UTC),\n",
    "                }\n",
    "                data_out.append(pline_out)\n",
    "    posts_df = pd.DataFrame(data_out)\n",
    "    print (f\"Found {len(posts_df)} posts\")\n",
    "    ## Filter posts to ensure they contain a question mark and must have at least two comments\n",
    "    posts_df = posts_df[((posts_df[\"contains_q\"] > 0) & (posts_df[\"num_comments\"] > 2))]\n",
    "    print (f\"Keeping only interrogative posts and posts with at least 2 comments, we have {len(posts_df)} posts\")\n",
    "    return posts_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27bc2e63-8b33-4e4f-a6c5-0325dc33dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joining_posts_with_comments(fpath, posts_df):\n",
    "    st = time.time()\n",
    "    post_ids = posts_df[\"post_id\"].to_list()\n",
    "    cnt = 0 \n",
    "    data_out = []\n",
    "    filesize = os.path.getsize(fpath)\n",
    "    with open(fpath) as f, tqdm(total=filesize, unit=\"B\", unit_scale=True, desc=\"Parsing\") as pbar:\n",
    "        for line in f:\n",
    "            pline = json.loads(line)\n",
    "            print (pline)\n",
    "            break\n",
    "            pbar.update(len(line))\n",
    "            tlevel, post_id = pline[\"parent_id\"].split(\"_\")\n",
    "            if (tlevel == \"t3\") and (post_id in post_ids):\n",
    "                cnt += 1\n",
    "                pline_out = {\n",
    "                    \"post_id\": post_id,\n",
    "                    \"comment_id\": pline[\"parent_id\"],\n",
    "                    \"comment_score\": pline.get(\"score\", np.nan), \n",
    "                    \"comment_ups\": pline.get(\"ups\", np.nan), \n",
    "                    \"comment_downs\": pline.get(\"downs\", np.nan), \n",
    "                    \"comment_controversiality\": pline.get(\"controversiality\", np.nan),\n",
    "                    \"comment_body\": pline.get(\"body\", np.nan),\n",
    "                    \"comment_distinguished\": pline.get(\"distinguished\", np.nan),\n",
    "                    ## when was the post made?\n",
    "                    'comment_created_utc': int(pline['created_utc']),\n",
    "                    'comment_created_utc_dt': datetime.fromtimestamp(int(pline['created_utc']), UTC)\n",
    "                }\n",
    "                data_out.append(pline_out)\n",
    "    comments_df = pd.DataFrame(data_out)\n",
    "    print (f\"Found {len(comments_df)} comments\")\n",
    "    ## Joining posts with comments\n",
    "    posts_df = posts_df.merge(comments_df, on=\"post_id\", how=\"inner\")\n",
    "    print (f\"After joining posts and comments, df len is {len(posts_df)}\")\n",
    "    print (f\"Time taken to parse posts and comments {(time.time()-st)/60.0} min\")\n",
    "    return posts_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29bf1f8e-a2bf-4479-92a9-03844435bdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 186947 posts\n",
      "Keeping only interrogative posts and posts with at least 2 comments, we have 132942 posts\n"
     ]
    }
   ],
   "source": [
    "## Get interrogative posts with at least 2 comments\n",
    "posts_df = get_posts(POSTS_FPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3039b9e0-c6b1-41d7-86a1-1b37294efc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get comments per post - done once and saved\n",
    "# data_df = joining_posts_with_comments(COMMENTS_FPATH, posts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f74b10a-3af6-4cd4-894c-a5041eabda14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Save filtered posts-comments to file\n",
    "# st = time.time()\n",
    "# data_df.to_pickle(\"posts_comments_df.pkl\")\n",
    "# print (f\"Time taken to write file = {(time.time()-st)/60.0}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cb939eb-c16f-4b16-91ad-5e1339349063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts-comments samples = 1825072\n",
      "Time taken to read file = 0.012884684403737386\n",
      "Number of posts-comments samples after removing empty ones = 1736315\n",
      "Number of posts for which we have comments after removing empty ones = 132907\n"
     ]
    }
   ],
   "source": [
    "## Open filtered posts-comments from file\n",
    "st = time.time()\n",
    "data_df = pd.read_pickle(INTERIM_OUTPUT_PATH)\n",
    "print (f\"Number of posts-comments samples = {len(data_df)}\")\n",
    "print (f\"Time taken to read file = {(time.time()-st)/60.0}\")\n",
    "\n",
    "## Remove empty/ deleted comments\n",
    "data_df = data_df[~(data_df[\"comment_body\"].str.strip().isin([\"[deleted]\", \"[removed]\", \"\", np.nan]))]\n",
    "print (f\"Number of posts-comments samples after removing empty ones = {len(data_df)}\")\n",
    "print (f\"Number of posts for which we have comments after removing empty ones = {data_df['post_id'].nunique()}\")\n",
    "\n",
    "## Add comment body length\n",
    "data_df[\"comment_body_original\"] = data_df[\"comment_body\"]\n",
    "data_df[\"comment_body\"] = data_df[\"comment_body\"].str.replace(\n",
    "    r\"http\\S+|www\\.\\S+\", \"\", regex=True, flags=re.IGNORECASE\n",
    ")\n",
    "data_df[\"comment_body\"] = (\n",
    "    data_df[\"comment_body\"]\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)  # collapse multiple spaces\n",
    "    .str.strip()                           # trim edges\n",
    ")\n",
    "\n",
    "data_df[\"comment_body_len\"] = data_df[\"comment_body\"].str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfbabcaa-d5e1-4a1c-9270-616178b3e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Looking at some stats on posts -- commented out\n",
    "\n",
    "# display(data_df[[\"score\", \"comment_body_len\"]].describe())\n",
    "\n",
    "# display(data_df[[\"score\", \"comment_body_len\"]].min())\n",
    "\n",
    "# ## The one letter/ short comments are likely nonsense.\n",
    "# display(data_df[[\"score\", \"comment_body_len\"]].quantile(.05))\n",
    "\n",
    "# res = pearsonr(data_df[\"score\"], data_df[\"comment_body_len\"])\n",
    "# print (res)\n",
    "\n",
    "## Outputting scatter plot\n",
    "# fig = px.scatter(data_df, x=\"score\", y=\"comment_body_len\")\n",
    "# fig.add_hline(y=5, line_color=\"red\", line_dash=\"dash\")\n",
    "# fig.write_image(\"scatter.png\")\n",
    "\n",
    "## We see a small negative correlation that is statistically significant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "876eb8b4-5bfa-453c-bc25-92140cf6c19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3y/zpvkkkdd1lxgc3cq5xvcmnn00000gn/T/ipykernel_30462/724647747.py:24: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  posts_data_df = data_df.groupby(\"post_id\").apply(get_comment_stats_per_post, include_groups=True).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts after grouping by on comments = 132907\n",
      "Number of posts after concatting everything = 132907\n"
     ]
    }
   ],
   "source": [
    "## Compute stats for comments and fetch top comment per post\n",
    "def get_comment_stats_per_post(df_grp):\n",
    "    return pd.Series({\n",
    "        ## count\n",
    "        \"num_comments_filtered\": len(df_grp),\n",
    "        ## score stats\n",
    "        \"min_comments_score\": df_grp[\"comment_score\"].min(),\n",
    "        \"max_comments_score\": df_grp[\"comment_score\"].max(),\n",
    "        \"median_comments_score\": df_grp[\"comment_score\"].median(),\n",
    "        \"mean_comments_score\": df_grp[\"comment_score\"].mean(),\n",
    "        \"range_comments_score\": df_grp[\"comment_score\"].max()-df_grp[\"comment_score\"].min(),\n",
    "        \"std_comments_score\": df_grp[\"comment_score\"].std(),\n",
    "        ## len stats\n",
    "        \"shortest_comments_len\": df_grp[\"comment_body_len\"].min(),\n",
    "        \"longest_comments_len\": df_grp[\"comment_body_len\"].max(),\n",
    "        \"median_comments_len\": df_grp[\"comment_body_len\"].median(),\n",
    "        \"mean_comments_len\": df_grp[\"comment_body_len\"].mean(),\n",
    "        \"range_comment_len\": df_grp[\"comment_body_len\"].max()-df_grp[\"comment_body_len\"].min(),\n",
    "        \"std_comments_len\": df_grp[\"comment_body_len\"].std()\n",
    "\n",
    "    })\n",
    "\n",
    "## Get per comment stats per post \n",
    "posts_data_df = data_df.groupby(\"post_id\").apply(get_comment_stats_per_post, include_groups=True).reset_index()\n",
    "print (f\"Number of posts after grouping by on comments = {len(posts_data_df)}\")\n",
    "\n",
    "## Fetch top comment per post\n",
    "top_comment_df = data_df.loc[data_df.groupby(\"post_id\")[\"comment_score\"].idxmax()]\n",
    "\n",
    "## Merge all together\n",
    "posts_data_df = posts_data_df.merge(top_comment_df, how=\"inner\", on=\"post_id\")\n",
    "print (f\"Number of posts after concatting everything = {len(posts_data_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1ea6c32-7234-4906-ba0c-11882be53748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['post_id', 'num_comments_filtered', 'min_comments_score',\n",
       "       'max_comments_score', 'median_comments_score', 'mean_comments_score',\n",
       "       'range_comments_score', 'std_comments_score', 'shortest_comments_len',\n",
       "       'longest_comments_len', 'median_comments_len', 'mean_comments_len',\n",
       "       'range_comment_len', 'std_comments_len', 'title', 'selftext',\n",
       "       'link_flair_text', 'title_len', 'selftext_len', 'score', 'ups',\n",
       "       'num_comments', 'title_contains_q', 'selftext_contains_q', 'contains_q',\n",
       "       'title_ends_q', 'selftext_ends_q', 'ends_q', 'created_utc',\n",
       "       'created_utc_dt', 'comment_id', 'comment_score', 'comment_ups',\n",
       "       'comment_downs', 'comment_controversiality', 'comment_body',\n",
       "       'comment_distinguished', 'comment_created_utc',\n",
       "       'comment_created_utc_dt', 'comment_body_original', 'comment_body_len'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(posts_data_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26072863-eeaf-48b2-8545-4ec4926e8074",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Looking at some stats of comments -- commented out\n",
    "\n",
    "# display(posts_data_df[[\n",
    "#                 \"score\",\n",
    "#                 \"num_comments\",\n",
    "#                 \"num_comments_filtered\",\n",
    "#                 \"min_comments_score\",\n",
    "#                 \"max_comments_score\",\n",
    "#                 \"range_comments_score\",\n",
    "#                 \"std_comments_score\",\n",
    "#                 \"comment_body_len\",\n",
    "#                 \"comment_score\"\n",
    "# ]].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2959a34-53e0-4496-8571-5c4bcb285965",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Format output for mistral and count tokens\n",
    "def get_chat_template(row):\n",
    "    system_prompt = \"You are a friendly parenting companion who gives helpful advice like a fellow parent would. You sound warm and practical — not robotic or formal.\"\n",
    "    user_prompt = f\"User's Prompt: {row['title']} - {row['selftext']}\"\n",
    "    assistant_prompt = row['comment_body']\n",
    "    chat = [\n",
    "        {\"role\": \"user\", \"content\": f\"{system_prompt} {user_prompt}\"},\n",
    "        {\"role\": \"assistant\", \"content\": assistant_prompt}\n",
    "    ]\n",
    "    row[\"chat\"] = chat\n",
    "    row[\"text\"] = TOKENIZER.apply_chat_template(chat, tokenize=False)\n",
    "    row[\"num_tokens\"] = len(TOKENIZER.apply_chat_template(chat, tokenize=True))\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c73242ca-9a3d-438d-8ee3-a989f4f87780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of posts before mistral formatting = 61487\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>comment_body_len</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61487.000000</td>\n",
       "      <td>61487.000000</td>\n",
       "      <td>61487.000000</td>\n",
       "      <td>61487.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>65.513881</td>\n",
       "      <td>511.209573</td>\n",
       "      <td>75.816238</td>\n",
       "      <td>502.434547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>233.503825</td>\n",
       "      <td>561.638058</td>\n",
       "      <td>220.156871</td>\n",
       "      <td>339.874821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>281.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>414.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>624.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>618.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6206.000000</td>\n",
       "      <td>9974.000000</td>\n",
       "      <td>7741.000000</td>\n",
       "      <td>7175.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score  comment_body_len  comment_score    num_tokens\n",
       "count  61487.000000      61487.000000   61487.000000  61487.000000\n",
       "mean      65.513881        511.209573      75.816238    502.434547\n",
       "std      233.503825        561.638058     220.156871    339.874821\n",
       "min        0.000000         55.000000      10.000000     75.000000\n",
       "25%        4.000000        184.000000      14.000000    281.000000\n",
       "50%       11.000000        342.000000      22.000000    414.000000\n",
       "75%       32.000000        624.000000      47.000000    618.000000\n",
       "max     6206.000000       9974.000000    7741.000000   7175.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% percentile of num_tokens = 1133.0\n",
      "99% percentile of num_tokens = 1764.2799999999988\n",
      "Final number of posts after removing posts with more than 620 tokens = 46181\n"
     ]
    }
   ],
   "source": [
    "## Filter posts by to get final post-comment pairs\n",
    "final_df = posts_data_df.copy(deep=True)\n",
    "\n",
    "EXCLUDED_FLAIRS = [\n",
    "    # We don't want to focus on adults\n",
    "    'Adult Children 18+ Years',\n",
    "    'Adult Children',\n",
    "    # These posts are not typically questions\n",
    "    'Update',\n",
    "    'short, happy rant ',\n",
    "    # We don't want admin posts\n",
    "    'Meta',\n",
    "    'meta',\n",
    "    # AMAs typically flips the conversational/ Q and A i.e. the comments are in fact questions\n",
    "    'confirmed AMA',\n",
    "    'AMA - mod approved',\n",
    "    # Weekly also flips the conversational/ Q and A format\n",
    "    'Weekly',\n",
    "    # Very few posts on these topics and th ey don't seem informative\n",
    "    'LOCKED',\n",
    "    'Locked',\n",
    "    'Trigger Warning: death and loss'\n",
    "]\n",
    "\n",
    "#### Filter by top comment length and score and exclude some post categories\n",
    "final_df = final_df[( \n",
    "    ~(final_df[\"link_flair_text\"].isin(EXCLUDED_FLAIRS)) &\n",
    "    (final_df[\"comment_score\"] >= 10) & \n",
    "    (final_df[\"comment_body_len\"] >= 55) \n",
    ")]\n",
    "\n",
    "print (f\"Final number of posts before mistral formatting = {len(final_df)}\")\n",
    "\n",
    "\n",
    "\n",
    "# ## Count categories/ flairs -- commented out\n",
    "# flair_vcs = pd.DataFrame({\n",
    "#     \"count\": final_df[\"link_flair_text\"].value_counts(),\n",
    "#     \"percent\": final_df[\"link_flair_text\"].value_counts(normalize=True) * 100\n",
    "# }).reset_index()\n",
    "# flair_vcs.columns = [\"flair\", \"count\", \"percent\"]\n",
    "# flair_vcs[\"percent\"] = flair_vcs[\"percent\"].round(2)  # optional\n",
    "# display(flair_vcs)\n",
    "\n",
    "\n",
    "final_df = final_df.apply(get_chat_template, axis=1)\n",
    "\n",
    "display(final_df[[\n",
    "        \"score\",\n",
    "        \"comment_body_len\",\n",
    "        \"comment_score\",\n",
    "        \"num_tokens\"\n",
    "]].describe())\n",
    "\n",
    "print (f\"95% percentile of num_tokens = {final_df['num_tokens'].quantile(0.95)}\")\n",
    "print (f\"99% percentile of num_tokens = {final_df['num_tokens'].quantile(0.99)}\")\n",
    "\n",
    "## Remove comments with too many tokens because longer might be harder to train on a single GPU\n",
    "final_df = final_df[(final_df[\"num_tokens\"] < MAX_TOKENS)]\n",
    "print (f\"Final number of posts after removing posts with more than {MAX_TOKENS} tokens = {len(final_df)}\")\n",
    "\n",
    "## Output to file\n",
    "final_df.to_json(OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1503d29d-478a-41fa-8847-0e98293bec34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>comment_body_len</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>46181.000000</td>\n",
       "      <td>46181.000000</td>\n",
       "      <td>46181.000000</td>\n",
       "      <td>46181.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>59.209913</td>\n",
       "      <td>370.818887</td>\n",
       "      <td>69.794786</td>\n",
       "      <td>353.770793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>220.940857</td>\n",
       "      <td>288.962163</td>\n",
       "      <td>206.922421</td>\n",
       "      <td>128.884239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>249.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>344.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>490.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>454.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6206.000000</td>\n",
       "      <td>2409.000000</td>\n",
       "      <td>7741.000000</td>\n",
       "      <td>619.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score  comment_body_len  comment_score    num_tokens\n",
       "count  46181.000000      46181.000000   46181.000000  46181.000000\n",
       "mean      59.209913        370.818887      69.794786    353.770793\n",
       "std      220.940857        288.962163     206.922421    128.884239\n",
       "min        0.000000         55.000000      10.000000     75.000000\n",
       "25%        4.000000        161.000000      13.000000    249.000000\n",
       "50%       10.000000        287.000000      21.000000    344.000000\n",
       "75%       28.000000        490.000000      43.000000    454.000000\n",
       "max     6206.000000       2409.000000    7741.000000    619.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(final_df[[\n",
    "        \"score\",\n",
    "        \"comment_body_len\",\n",
    "        \"comment_score\",\n",
    "        \"num_tokens\"\n",
    "]].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfba60e5-5b18-4526-bafe-2afa7f21dec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>num_comments_filtered</th>\n",
       "      <th>min_comments_score</th>\n",
       "      <th>max_comments_score</th>\n",
       "      <th>median_comments_score</th>\n",
       "      <th>mean_comments_score</th>\n",
       "      <th>range_comments_score</th>\n",
       "      <th>std_comments_score</th>\n",
       "      <th>shortest_comments_len</th>\n",
       "      <th>longest_comments_len</th>\n",
       "      <th>...</th>\n",
       "      <th>comment_controversiality</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>comment_distinguished</th>\n",
       "      <th>comment_created_utc</th>\n",
       "      <th>comment_created_utc_dt</th>\n",
       "      <th>comment_body_original</th>\n",
       "      <th>comment_body_len</th>\n",
       "      <th>chat</th>\n",
       "      <th>text</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10027tn</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.454972</td>\n",
       "      <td>91.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>In general the advice is to tell them early an...</td>\n",
       "      <td>None</td>\n",
       "      <td>1672518619</td>\n",
       "      <td>2022-12-31 20:30:19+00:00</td>\n",
       "      <td>In general the advice is to tell them early an...</td>\n",
       "      <td>670</td>\n",
       "      <td>[{'role': 'user', 'content': 'You are a friend...</td>\n",
       "      <td>&lt;s&gt;[INST] You are a friendly parenting compani...</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1002kbu</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.833333</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.183736</td>\n",
       "      <td>2.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Turning red by Pixar. Thought I'd be annoyed b...</td>\n",
       "      <td>None</td>\n",
       "      <td>1672517781</td>\n",
       "      <td>2022-12-31 20:16:21+00:00</td>\n",
       "      <td>Turning red by Pixar. Thought I'd be annoyed b...</td>\n",
       "      <td>124</td>\n",
       "      <td>[{'role': 'user', 'content': 'You are a friend...</td>\n",
       "      <td>&lt;s&gt;[INST] You are a friendly parenting compani...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  num_comments_filtered  min_comments_score  max_comments_score  \\\n",
       "3  10027tn                    4.0                 2.0                16.0   \n",
       "4  1002kbu                   12.0                 2.0                24.0   \n",
       "\n",
       "   median_comments_score  mean_comments_score  range_comments_score  \\\n",
       "3                    4.0             6.500000                  14.0   \n",
       "4                    7.0             9.833333                  22.0   \n",
       "\n",
       "   std_comments_score  shortest_comments_len  longest_comments_len  ...  \\\n",
       "3            6.454972                   91.0                 670.0  ...   \n",
       "4            7.183736                    2.0                 250.0  ...   \n",
       "\n",
       "   comment_controversiality  \\\n",
       "3                         0   \n",
       "4                         0   \n",
       "\n",
       "                                        comment_body  comment_distinguished  \\\n",
       "3  In general the advice is to tell them early an...                   None   \n",
       "4  Turning red by Pixar. Thought I'd be annoyed b...                   None   \n",
       "\n",
       "   comment_created_utc    comment_created_utc_dt  \\\n",
       "3           1672518619 2022-12-31 20:30:19+00:00   \n",
       "4           1672517781 2022-12-31 20:16:21+00:00   \n",
       "\n",
       "                               comment_body_original comment_body_len  \\\n",
       "3  In general the advice is to tell them early an...              670   \n",
       "4  Turning red by Pixar. Thought I'd be annoyed b...              124   \n",
       "\n",
       "                                                chat  \\\n",
       "3  [{'role': 'user', 'content': 'You are a friend...   \n",
       "4  [{'role': 'user', 'content': 'You are a friend...   \n",
       "\n",
       "                                                text  num_tokens  \n",
       "3  <s>[INST] You are a friendly parenting compani...         362  \n",
       "4  <s>[INST] You are a friendly parenting compani...         140  \n",
       "\n",
       "[2 rows x 44 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd141133-9810-43e0-b4e6-6ba62aac5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing examples of short comments\n",
    "# print (final_df[\"comment_body_len\"].min())\n",
    "# tmp_df = final_df[(final_df[\"comment_body_len\"] == final_df[\"comment_body_len\"].min())]\n",
    "\n",
    "# for i in range(0, 3):\n",
    "#     print (\"\\n\\n-----\")\n",
    "#     print (f\"TITLE: {tmp_df['title'].iloc[i]}\")\n",
    "#     print (f\"BODY: {tmp_df['selftext'].iloc[i]}\")\n",
    "#     print (f\"\\nANSWER (len: {tmp_df['comment_body_len'].iloc[i]}, sc: {tmp_df['comment_score'].iloc[i]}):\\n {tmp_df['comment_body'].iloc[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c4c1124-2e60-4f00-8fee-d55487783319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Spot checking categories\n",
    "# sel_cats = [\n",
    "#     # 'Rant',\n",
    "#     # 'misc',\n",
    "#     # 'media',\n",
    "#     # 'SUPPORT',\n",
    "#     # 'Rave',\n",
    "#     # 'Support',\n",
    "#     # 'Weekly',\n",
    "#     'weird phobia'\n",
    "# ]\n",
    "\n",
    "# for s in sel_cats:\n",
    "#     tmp_df = final_df[(final_df[\"link_flair_text\"] == s)]\n",
    "#     for i in range(0, 3):\n",
    "#         print (f\"\\n\\n-----\\n{s}: {i+1}\")\n",
    "#         print (f\"TITLE: {tmp_df['title'].iloc[i]}\")\n",
    "#         print (f\"BODY: {tmp_df['selftext'].iloc[i]}\")\n",
    "#         print (f\"\\nANSWER ({tmp_df['comment_body_len'].iloc[i]}): {tmp_df['comment_body'].iloc[i]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "060e637a-7cf1-44bd-9bf9-9a0793865d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38400\n"
     ]
    }
   ],
   "source": [
    "train_size_sel = int((len(final_df)*0.85)/2400)*2400 # Rounded off is better\n",
    "print(train_size_sel)\n",
    "\n",
    "## Split into Training and Validation Datasets\n",
    "cols = [\n",
    "    \"post_id\",\n",
    "    \"comment_id\",\n",
    "    \"text\",\n",
    "    \"num_tokens\"\n",
    "]\n",
    "train_df, val_df = train_test_split(final_df, train_size=train_size_sel, random_state=42)\n",
    "train_df[cols].to_json(TRAIN_DATASET_FPATH, orient='records', lines=True)\n",
    "val_df[cols].to_json(VAL_DATASET_FPATH, orient='records', lines=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe62d495-c6b1-42be-92fc-0b194e764f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 38400\n",
      "Number of validation examples: 7781\n"
     ]
    }
   ],
   "source": [
    "print (f\"Number of training examples: {len(train_df)}\")\n",
    "print (f\"Number of validation examples: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c49ccc0-efea-4e9a-b4cb-350e957b881c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s>[INST] You are a friendly parenting companion who gives helpful advice like a fellow parent would. You sound warm and practical — not robotic or formal. User's Prompt: The million dollar question - Apparently, my 6yrs old just found out about the word 'sex' and came asking. First I tried to wrapped my head around a suitable response while trying to find out where she heard it from, she quickly screamed 'school' cutting short my thinking time. Personally, I thought this was not a topic you say 'let's talk about this later, so I posed more questions to buy time; who mentioned it in school and how did they talk about it, what was the explanation you got? She tried mumbling some stuff, right then I had to say 'give me a moment we will talk about this later. What's the best way to approach this? [/INST] There is absolutely nothing wrong with saying “I’m not sure how to answer that, let me think about it and get back to you.” The key is you HAVE to follow up. Basic simple explanation. Don’t give more than what they are asking for.</s>\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"text\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d00e7be4-7d10-4e9c-af95-931c69f7569d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation examples to quick eval on: 100\n"
     ]
    }
   ],
   "source": [
    "## Pick 100 random validation examples and create another dataset for quick eval\n",
    "VAL_DATASET_100_FPATH = os.path.join(DATA_FOLDER, \"reddit_dataset_val_100.jsonl\")\n",
    "val_df_100 = val_df.sample(n=100, random_state=42)\n",
    "print (f\"Number of validation examples to quick eval on: {len(val_df_100)}\")\n",
    "val_df_100[cols].to_json(VAL_DATASET_100_FPATH, orient='records', lines=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753616f-931c-4443-9ea5-d42006940e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
